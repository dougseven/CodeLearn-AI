{
    "lesson": "# Memory Management and Performance Optimization in Python\n\n## Introduction\nMemory management and performance optimization are critical skills for advanced Python developers, especially when dealing with large-scale applications and data-intensive processing.\n\n## Memory Management Concepts\n\n### Reference Counting and Garbage Collection\n```python\n# Reference counting example\nimport sys\n\nx = [1, 2, 3]  # Creates object\nref_count = sys.getrefcount(x)  # Check reference count\n```\n\n### Memory Profiling\n```python\nimport memory_profiler\n\n@memory_profiler.profile\ndef memory_intensive_function():\n    # Analyze memory usage\n    large_list = [i for i in range(1000000)]\n```\n\n### Object Optimization Techniques\n```python\n# Using generators for memory efficiency\ndef memory_efficient_generator():\n    for i in range(1000000):\n        yield i  # Generates values on-the-fly\n```\n\n## Key Performance Optimization Strategies\n- Use generators instead of lists for large datasets\n- Leverage `__slots__` for memory-efficient classes\n- Utilize `collections` module for optimized data structures\n- Minimize object creation and copying\n\n## Common Performance Bottlenecks\n- Unnecessary list comprehensions\n- Repeated function calls\n- Inefficient data structure selection\n- Unoptimized loops\n\n## Comparison with C# Memory Management\n- Python's garbage collection \u2248 C#'s automatic memory management\n- `list` \u2192 `List<T>`\n- `dict` \u2192 `Dictionary<TKey, TValue>`\n- Reference counting similar to .NET managed references\n\n## Best Practices\n- Profile before optimizing\n- Use `timeit` for performance measurements\n- Choose appropriate data structures\n- Avoid premature optimization\n\n## Practice Exercises\n```python\n# Exercise: Implement a memory-efficient prime number generator\ndef generate_primes(limit):\n    # TODO: Create a generator that yields prime numbers efficiently\n    pass\n```\n\n## Advanced Techniques\n- Use `functools.lru_cache` for memoization\n- Implement lazy evaluation patterns\n- Leverage NumPy for numerical computations",
    "challenge": "# Memory Optimization Challenge\n\ndef optimize_memory_usage(data):\n    '''\nImplement a memory-efficient function that:\n1. Processes large datasets without consuming excessive memory\n2. Uses a generator or memory-efficient data structure\n3. Handles input of varying sizes\n\nInput: A large list of integers\nOutput: Generator yielding processed values\n'''\n    pass",
    "tests": [
        "import sys\ndef test_memory_efficiency():\n    large_input = list(range(1000000))\n    result = optimize_memory_usage(large_input)\n    assert hasattr(result, '__iter__'), 'Result must be an iterator'\n    assert sys.getsizeof(result) < sys.getsizeof(large_input), 'Memory usage should be reduced'",
        "def test_processing_correctness():\n    test_data = [1, 2, 3, 4, 5]\n    result = list(optimize_memory_usage(test_data))\n    assert len(result) == len(test_data), 'Output length must match input'",
        "def test_large_dataset_handling():\n    large_input = list(range(10000))\n    result = list(optimize_memory_usage(large_input))\n    assert len(result) == len(large_input), 'Large dataset processing failed'"
    ]
}